@article{Hsia2016,
author = {Hsia, Chih-Hsien and Chiang, Jen-Shiun and Hsieh, Chi-Fang},
doi = {10.1007/s11042-015-2714-2},
file = {:C$\backslash$:/Users/user/Documents/Mendeley Desktop/Hsia, Chiang, Hsieh{\_}2016{\_}Low-complexity range tree for video synopsis system.pdf:pdf},
issn = {1380-7501},
journal = {Multimedia Tools and Applications},
keywords = {Gaussian mixture model,Low-complexity range tree,Object detection,Video retrieval system,Video synopsis system},
month = {Aug.},
number = {16},
pages = {9885--9902},
publisher = {Multimedia Tools and Applications},
title = {{Low-complexity range tree for video synopsis system}},
url = {http://dx.doi.org/10.1007/s11042-015-2714-2 http://link.springer.com/10.1007/s11042-015-2714-2},
volume = {75},
year = {2016}
}
@inproceedings{Jin2016,
author = {Jin, Jing and Liu, Feng and Gan, Zongliang and Cui, Ziguan},
booktitle = {2016 8th International Conference on Wireless Communications {\&} Signal Processing (WCSP)},
doi = {10.1109/WCSP.2016.7752708},
file = {:C$\backslash$:/Users/user/Documents/Mendeley Desktop/Jin et al.{\_}2016{\_}Online video synopsis method through simple tube projection strategy.pdf:pdf},
isbn = {978-1-5090-2860-3},
keywords = {buffer,collision,projection matrix,video synopsis},
month = {Oct.},
pages = {1--5},
publisher = {IEEE},
title = {{Online video synopsis method through simple tube projection strategy}},
url = {http://ieeexplore.ieee.org/document/7752708/},
volume = {1},
year = {2016}
}
@article{Mahapatra2016,
	author = {Mahapatra, Ansuman and Sa, Pankaj K. and Majhi, Banshidhar and Padhy, Sudarshan},
	doi = {10.1016/j.image.2016.01.002},
	isbn = {9781479983391},
	issn = {09235965},
	journal = {Signal Processing: Image Communication},
	keywords = {Multi-camera network,Multi-view video,Video summarization,Video synopsis},
	month = {Mar.},
	pages = {31--44},
	publisher = {Elsevier},
	title = {{MVS: A multi-view video synopsis framework}},
	url = {http://dx.doi.org/10.1016/j.image.2016.01.002},
	volume = {42},
	year = {2016}
}
@article{Lin2015,
abstract = {{\textcopyright} 2015 Springer-Verlag Berlin Heidelberg Video synopsis is one of the popular research topics in the field of digital video and has broad application prospects. Current research of it focuses on the methods of generating video synopsis or studying to utilize optimization algorithms such as fuzzy theory, minimum sparse reconstruction, and genetic algorithm to optimize its computing steps. This paper mainly studies the object-based video synopsis technology in distributed environment. We propose an effective video synopsis algorithm and a distributed processing model to accelerate the computing speed of video synopsis. The algorithm is proposed for studies of surveillance videos, which focuses on several key algorithmic steps, for instance, initialization of original video resources, background modeling, moving object detecting, and nonlinear rearrangement. These steps can be performed in parallel. In order to obtain good video synopsis effect and fast computing speed, some optimization methods are applied to these steps. With the aim of employing much more computing resources, we propose a distributed processing model, which splits the original video file into multiple segments and distributes them to different computing nodes to improve the computing performance by leveraging the multi-core and multi-thread capabilities of CPU. Experimental results show that the proposed distributed model can significantly improve the computing speed of video synopsis.},
author = {Lin, Longxin and Lin, Weiwei and Xiao, Weijun and Huang, Sibin},
doi = {10.1007/s00500-015-1823-1},
file = {:C$\backslash$:/Users/user/Documents/Mendeley Desktop/Lin et al.{\_}2015{\_}An optimized video synopsis algorithm and its distributed processing model.pdf:pdf},
issn = {1432-7643},
journal = {Soft Computing},
keywords = {Distributed processing,Fuzzy C means,Fuzzy set theory,Genetic algorithm,Multi-thread,Sparse reconstruction,Video surveillance,Video synopsis},
month = {Feb.},
number = {4},
pages = {935--947},
publisher = {Springer Berlin Heidelberg},
title = {{An optimized video synopsis algorithm and its distributed processing model}},
url = {http://link.springer.com/10.1007/s00500-015-1823-1},
volume = {21},
year = {2015}
}
@article{He2017,
	author = {He, Yi and Qu, Zhiguo and Gao, Changxin and Sang, Nong},
	doi = {10.1109/LSP.2016.2633374},
	issn = {1070-9908},
	journal = {IEEE Signal Processing Letters},
	month = {Jan.},
	number = {1},
	pages = {22--26},
	title = {{Fast Online Video Synopsis Based on Potential Collision Graph}},
	url = {http://ieeexplore.ieee.org/document/7762044/},
	volume = {24},
	year = {2017}
}
@article{He2017a,
abstract = {Abstract Video synopsis is an intelligent condensation approach to solve fast video browsing and retrieval for surveillance cameras. However, collision caused by unsatisfied tube rearrangement in traditional methods brings uncomfortable visual effect to users and how to mitigate the collision still remains an attracting topic. Unlike conventional methods that deal with tube rearrangement by minimizing a global energy function, we propose a novel approach by formulating it as a graph coloring problem. In our approach, all the tubes are firstly mapped into the spatial domain for analyzing their potential collision relationship. The input tube set is then represented by a graph structure, where each node stands for a tube and the edge between two nodes represents the potential collision relationship. To mitigate the collision artifacts, our method finds the mapping of tubes from original video to synopsis video by L(q)-coloring the graph, which separates tubes from their collision points. The parameter q is left tunable to make a compromise between collision artifacts and synopsis length, which can better meet users' demand of freely adjusting the compactness of synopsis video. The shifted objects are finally composited with the background image to obtain the high-quality video synopsis. Extensive experimental results show that the proposed method can generate more compact video synopsis with less collision artifacts than the existing methods.},
author = {He, Yi and Gao, Changxin and Sang, Nong and Qu, Zhiguo and Han, Jun},
doi = {10.1016/j.neucom.2016.11.011},
file = {:C$\backslash$:/Users/user/Documents/Mendeley Desktop/He et al.{\_}2017{\_}Graph coloring based surveillance video synopsis.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Graph coloring,Tube rearrangement,Video synopsis},
month = {Feb.},
number = {September 2016},
pages = {64--79},
title = {{Graph coloring based surveillance video synopsis}},
url = {http://www.sciencedirect.com/science/article/pii/S0925231216313406 http://linkinghub.elsevier.com/retrieve/pii/S0925231216313406},
volume = {225},
year = {2017}
}
@inproceedings{Hoshen2015,
abstract = {Video surveillance cameras generate most of recorded video, and there is far more recorded video than operators can watch. Much progress has recently been made using summarization of recorded video, but such techniques do not have much impact on live video surveillance. We assume a camera hierarchy where a Master camera observes the decision-critical region, and one or more Slave cameras observe regions where past activity is important for making the current decision. We propose that when people appear in the live Master camera, the Slave cameras will display their past activities, and the operator could use past information for real-time decision making. The basic units of our method are action tubes, representing objects and their trajectories over time. Our object-based method has advantages over frame based methods, as it can handle multiple people, multiple activities for each person, and can address re-identification uncertainty.},
archivePrefix = {arXiv},
arxivId = {1505.05254},
author = {Hoshen, Yedid and Peleg, Shmuel},
booktitle = {2015 IEEE International Conference on Image Processing (ICIP)},
doi = {10.1109/ICIP.2015.7350790},
eprint = {1505.05254},
file = {:C$\backslash$:/Users/user/Documents/Mendeley Desktop/Hoshen, Peleg{\_}2015{\_}Live video synopsis for multiple cameras.pdf:pdf},
isbn = {978-1-4799-8339-1},
issn = {15224880},
keywords = {Multi Camera Synopsis,Video Surveillance,Video Synopsis},
month = {Sep.},
pages = {212--216},
publisher = {IEEE},
title = {{Live video synopsis for multiple cameras}},
url = {http://ieeexplore.ieee.org/document/7350790/},
volume = {2015-Decem},
year = {2015}
}
@article{RuiZhong2014,
	author = {{Rui Zhong} and {Ruimin Hu} and {Zhongyuan Wang} and {Shizheng Wang}},
	doi = {10.1109/LSP.2014.2317754},
	issn = {1070-9908},
	journal = {IEEE Signal Processing Letters},
	month = {Jul.},
	number = {7},
	pages = {834--838},
	title = {{Fast Synopsis for Moving Objects Using Compressed Video}},
	url = {http://ieeexplore.ieee.org/document/6805196/},
	volume = {21},
	year = {2014}
}
@article{Li2016,
	author = {Li, Ke and Yan, Bo and Wang, Weiyi and Gharavi, Hamid},
	doi = {10.1109/LSP.2015.2496558},
	isbn = {1070-9908 VO - 23},
	issn = {1070-9908},
	journal = {IEEE Signal Processing Letters},
	month = {Jan.},
	number = {1},
	pages = {11--14},
	title = {{An Effective Video Synopsis Approach with Seam Carving}},
	url = {http://ieeexplore.ieee.org/document/7312927/},
	volume = {23},
	year = {2016}
}
@article{Fu2014,
	author = {Fu, Wei and Wang, Jinqiao and Gui, Liangke and Lu, Hanqing and Ma, Songde},
	title = {{Online video synopsis of structured motion}},
	journal = {Neurocomputing},
	volume = {135},
	pages = {155--162},
	month = {Jul.},
	year = {2014},
	doi = {10.1016/j.neucom.2013.12.041},
	url = {https://doi.org/10.1016/j.neucom.2013.12.041},
}
@article{ZhuangLi2009,
	author = {{Zhuang Li} and Ishwar, Prakash and Konrad, Janusz},
	doi = {10.1109/TIP.2009.2026677},
	isbn = {1057-7149},
	issn = {1057-7149},
	journal = {IEEE Transactions on Image Processing},
	month = {Nov.},
	number = {11},
	pages = {2572--2583},
	pmid = {19586819},
	title = {{Video Condensation by Ribbon Carving}},
	url = {http://ieeexplore.ieee.org/document/5156267/},
	volume = {18},
	year = {2009}
}
@article{Wang2013,
	author = {Wang, Shi-Zheng and Wang, Zhong-Yuan and Hu, Rui-Min},
	title = {{Surveillance video synopsis in the compressed domain for fast video browsing}},
	journal = {Journal of Visual Communication and Image Representation},
	volume = {24},
	number = {8},
	pages = {1431--1442},
	month = {Nov.},
	year = {2013},
	doi = {10.1016/j.jvcir.2013.10.001},
	url = {http://doi.org/10.1016/j.jvcir.2013.10.001},
}
@article{Lin2015a,
abstract = {In this paper, we propose a new approach to detect abnormal activities in surveillance videos and create suitable summary videos accordingly. The proposed approach first introduces a patch-based method to automatically model normal activity patterns and key regions in a scene. In this way, abnormal activities can be effectively detected and classified from the modeled normal patterns and key regions. Then, a blob sequence optimization process is proposed which integrates spatial, temporal, size, and motion correlation among objects to extract suitable foreground blob sequences for abnormal objects. With this process, blob extraction errors due to occlusion or background interference can be effectively avoided. Finally, we also propose an abnormality-type-based method which creates short-period summary videos from long-period input surveillance videos by properly arranging abnormal blob sequences according to their activity types. Experimental results show that our proposed approach can effectively create satisfying summary videos from input surveillance videos.},
annote = {Cd2un Times Cited:5 Cited References Count:37},
author = {Lin, Weiyao and Zhang, Yihao and Lu, Jiwen and Zhou, Bing and Wang, Jinjun and Zhou, Yu},
doi = {10.1016/j.neucom.2014.12.044},
file = {:C$\backslash$:/Users/user/Documents/Mendeley Desktop/Lin et al.{\_}2015{\_}Summarizing surveillance videos with local-patch-learning-based abnormality detection, blob sequence optimization, and t.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Abnormality detection,Blob sequence optimization,Video synopsis},
language = {English},
month = {May},
pages = {84--98},
title = {{Summarizing surveillance videos with local-patch-learning-based abnormality detection, blob sequence optimization, and type-based synopsis}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231214017081},
volume = {155},
year = {2015}
}
@article{Li2016a,
	author = {Li, Xuelong and Wang, Zhigang and Lu, Xiaoqiang},
	doi = {10.1109/TIP.2015.2507942},
	issn = {1057-7149},
	journal = {IEEE Transactions on Image Processing},
	month = {Feb.},
	number = {2},
	pages = {740--755},
	title = {{Surveillance Video Synopsis via Scaling Down Objects}},
	url = {http://ieeexplore.ieee.org/document/7353185/},
	volume = {25},
	year = {2016}
}
@inproceedings{Tran2011,
abstract = {We propose a novel algorithm for video event detection and localization as the optimal path discovery problem in spatio-temporal video space. By finding the optimal spatio-temporal path, our method not only detects the starting and ending points of the event, but also accurately locates it in each video frame. Moreover, our method is robust to the scale and intra-class variations of the event, as well as false and missed local detections, therefore improves the overall detection and localization accuracy. The proposed search algorithm obtains the global optimal solution with proven lowest computational complexity. Experiments on realistic video datasets demonstrate that our proposed method can be applied to different types of event detection tasks, such as abnormal event detection and walking pedestrian detection.},
author = {Tran, Du and Yuan, Junsong},
booktitle = {2011 IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2011.5995416},
file = {:C$\backslash$:/Users/user/Documents/Mendeley Desktop/Tran, Yuan{\_}2011{\_}Optimal spatio-temporal path discovery for video event detection.pdf:pdf},
isbn = {978-1-4577-0394-2},
issn = {10636919},
month = {Jun.},
pages = {3321--3328},
publisher = {IEEE},
title = {{Optimal spatio-temporal path discovery for video event detection}},
url = {http://ieeexplore.ieee.org/document/5995416/},
year = {2011}
}
@inproceedings{Sun2012,
abstract = {By segmenting moving objects out and then densely stitching them into background frames, video synopsis provides an efficient way to condense long videos while preserving most activities. Existing video synopsis methods, however, often suffer from either high computation cost due to global energy minimization or unsatisfactory condense rate to avoid loss of important object activities. To address these problems, a tracking based fast online video synopsis approach is proposed in this paper which makes following three main contributions: 1) an online formulation of the video synopsis problem which makes the approach very fast and scalable to endless surveillance videos with reduced chronological disorders, 2) a tracking based schema which can preserve most object activities, and 3) a complete optimization process from both temporal and spatial redundancies of the video which results in much higher condense rate and less object conflict rate. Experimental results demonstrate the effectiveness and efficiency of proposed approach compared to the traditional method on public surveillance videos.},
author = {Sun, Lei and Xing, Junliang and Ai, Haizhou and Lao, Shihong},
booktitle = {Pattern Recognition (ICPR), 2012 21st International Conference on},
file = {:C$\backslash$:/Users/user/Documents/Mendeley Desktop/Sun et al.{\_}2012{\_}A tracking based fast online complete video synopsis approach.pdf:pdf},
isbn = {978-4-9906441-0-9},
issn = {1051-4651},
keywords = {image forensics,image motion analysis,image segmen},
pages = {1956--1959},
publisher = {IEEE},
title = {{A tracking based fast online complete video synopsis approach}},
year = {2012}
}
@article{Nguyen2016,
abstract = {Vision-based detection of illegal or accidental activities in urban traffic has attracted great interest. Since state-of-the-art online automated detection algorithms are far from perfect, much research effort on offline video surveillance has been made to prevent police or security staff from observing all recorded video frames unnecessarily. To solve the problem, this study focuses on video condensation, which provides fast monitoring of moving objects in a long duration of surveillance videos. Considering the computational complexity and the condensation ratio as the two main criteria for efficient video condensation, we propose a video condensation algorithm, which consists of the following: 1) initial condensation by discarding frames of nonmoving objects; 2) intra-GoFM (group of frames with moving objects) condensation; and 3) inter-GoFM condensation. In the intra-GoFM and inter-GoFM condensation, spatiotemporal static pixels within each GoFM and temporal static pixels between two consecutive GoFMs are dropped to shorten the temporal distances between consecutive moving objects. Experimental results show that our video condensation saves a significant amount of computational loads compared with the previous methods without sacrificing the condensation ratio and visual quality.},
annote = {Dv2tn Times Cited:0 Cited References Count:20},
author = {Nguyen, Hai Thanh and Jung, Seung-Won and Won, Chee Sun},
doi = {10.1109/TITS.2016.2518622},
file = {:C$\backslash$:/Users/user/Documents/Mendeley Desktop/Nguyen, Jung, Won{\_}2016{\_}Order-Preserving Condensation of Moving Objects in Surveillance Videos.pdf:pdf},
issn = {1524-9050},
journal = {IEEE Transactions on Intelligent Transportation Systems},
keywords = {Video signal processing,ribbon carving,transportation surveillance video,video condensation},
language = {English},
month = {Sep.},
number = {9},
pages = {2408--2418},
title = {{Order-Preserving Condensation of Moving Objects in Surveillance Videos}},
url = {http://ieeexplore.ieee.org/document/7422070/},
volume = {17},
year = {2016}
}
@inproceedings{Pritch2007,
	author = {Pritch, Yael and Rav-Acha, Alex and Gutman, Avital and Peleg, Shmuel},
	title = {{Webcam Synopsis: Peeking Around the World}},
	booktitle = {2007 IEEE 11th International Conference on Computer Vision},
	pages = {1--8},
	month = {Oct.},
	year = {2007},
	doi = {10.1109/ICCV.2007.4408934},
	url = {https://ieeexplore.ieee.org/document/4408934}
}
@inproceedings{Lu2013,
abstract = {Video synopsis is one of the effective techniques to build a short video representation preserving the essential activities for a long video. Existing methods usually have the problem that a continuous activity (tube) from a single moving object is separated to a few small pieces. In this paper, two schemes are proposed to generate fluent tubes for video synopsis. The Gaussian mixture model and a texture method are combined to detect more compact foreground with shadow removed. The foreground constitutes a set of initial trajectories. A particle filter tracker is used to concatenate two trajectories if they belong to the same foreground activity, which generates more fluent tubes for video synopsis. Experimental results on 4 videos show that our method produces better accuracies and visual effects in video synopsis.},
author = {Lu, Minlong and Wang, Yueming and Pan, Gang},
booktitle = {2013 IEEE International Conference on Acoustics, Speech and Signal Processing},
doi = {10.1109/ICASSP.2013.6638063},
file = {:C$\backslash$:/Users/user/Documents/Mendeley Desktop/Lu, Wang, Pan{\_}2013{\_}Generating fluent tubes in video synopsis.pdf:pdf},
isbn = {978-1-4799-0356-6},
issn = {15206149},
keywords = {fluent tube,particle filter,shadow removal,video synopsis},
month = {May},
pages = {2292--2296},
publisher = {IEEE},
title = {{Generating fluent tubes in video synopsis}},
url = {http://ieeexplore.ieee.org/document/6638063/},
year = {2013}
}
@article{Pritch2008,
	author = {Pritch, Yael and Rav-Acha, Alex and Peleg, Shmuel},
	doi = {10.1109/TPAMI.2008.29},
	isbn = {0162-8828},
	issn = {0162-8828},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Video indexing,Video summary,Video surveillance},
	month = {Nov.},
	number = {11},
	pages = {1971--1984},
	pmid = {18787245},
	title = {{Nonchronological Video Synopsis and Indexing}},
	url = {http://ieeexplore.ieee.org/document/4444355/},
	volume = {30},
	year = {2008}
}
@inproceedings{Wang2012,
abstract = {With extending applications of digital surveillance video, the fast browsing technique for surveillance video has become a hot spot in the domain. As one of the most important supporting technologies, region of interest (ROI) information coding is a necessary part of fast browsing framework for surveillance video. Therefore, a novel coding method of object region flags and successful application of object mapping flags for the scalable browsing of surveillance video are proposed in this paper. This object region flags coding method includes both intra-frame coding and inter-frame coding, wherein, the former eliminates the redundancy in spatial domain by improving the scanning mode of region flags, the latter eliminates the redundancy in temporal domain, which cuts coding cost obviously and provides essential supports for video synopsis browsing of surveillance video.},
author = {Wang, Shizheng and Liu, Heguang and Xie, Danfeng and Zeng, Binwei},
booktitle = {2012 Visual Communications and Image Processing},
doi = {10.1109/VCIP.2012.6410771},
file = {:C$\backslash$:/Users/user/Documents/Mendeley Desktop/Wang et al.{\_}2012{\_}A novel scheme to code object flags for video synopsis.pdf:pdf},
isbn = {978-1-4673-4407-4},
keywords = {Surveillance video,object flags,scalable browsing,video synopsis},
month = {Nov.},
pages = {1--5},
publisher = {IEEE},
title = {{A novel scheme to code object flags for video synopsis}},
url = {http://ieeexplore.ieee.org/document/6410771/},
year = {2012}
}
@article{Zhu2014,
	author = {Zhu, Xiaobin and Liu, Jing and Wang, Jinqiao and Lu, Hanqing},
	title = {{Key observation selection-based effective video synopsis for camera network}},
	journal = {Machine Vision and Applications},
	volume = {25},
	number = {1},
	pages = {145--157},
	month = {Jan.},
	year = {2014},
	doi = {10.1007/s00138-013-0519-8},
	url = {https://doi.org/10.1007/s00138-013-0519-8},
}
@inproceedings{Pritch2009,
	author = {Pritch, Yael and Ratovitch, Sarit and Hendel, Avishai and Peleg, Shmuel},
	booktitle = {2009 Sixth IEEE International Conference on Advanced Video and Signal Based Surveillance},
	doi = {10.1109/AVSS.2009.53},
	month = {Sep.},
	pages = {195--200},
	title = {{Clustered Synopsis of Surveillance Video}},
	url = {http://ieeexplore.ieee.org/document/5280098/},
	year = {2009}
}
@article{Zhu2016,
	author = {Zhu, Jianqing and Liao, Shengcai and Li, Stan Z.},
	doi = {10.1109/TCSVT.2015.2430692},
	issn = {1051-8215},
	journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	month = {Jun.},
	number = {6},
	pages = {1058--1069},
	title = {{Multicamera Joint Video Synopsis}},
	url = {http://ieeexplore.ieee.org/document/7103038/},
	volume = {26},
	year = {2016}
}
@inproceedings{ShikunFeng2012,
	author = {{Shikun Feng} and {Zhen Lei} and {Dong Yi} and Li, Stan Z.},
	title = {{Online content-aware video condensation}},
	booktitle = {2012 IEEE Conference on Computer Vision and Pattern Recognition},
	pages = {2082--2087},
	month = {Jun.},
	year = {2012},
	doi = {10.1109/CVPR.2012.6247913},
	url = {http://ieeexplore.ieee.org/document/6247913/},
}
@article{Nie2014,
	author = {Nie, Yongwei and Sun, Hanqiu and Li, Ping and Xiao, Chunxia and Ma, Kwan-Liu},
	doi = {10.1109/TVCG.2013.2297931},
	isbn = {1077-2626},
	issn = {1077-2626},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	month = {Sep.},
	number = {9},
	pages = {1303--1315},
	pmid = {26357379},
	title = {{Object Movements Synopsis via Part Assembling and Stitching}},
	url = {http://ieeexplore.ieee.org/document/6702519/},
	volume = {20},
	year = {2014}
}
@inproceedings{Rav-Acha2006,
	author = {Rav-Acha, Alex and Pritch, Yael and Peleg, Shmuel},
	title = {{Making a Long Video Short: Dynamic Video Synopsis}},
	booktitle = {2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	volume = {1},
	pages = {435--441},
	month = {Jun.},
	year = {2006},
	doi = {10.1109/CVPR.2006.179},
	url = {http://ieeexplore.ieee.org/document/1640790/},
}
@inproceedings{Chien-LiChou2015,
author = {{Chien-Li Chou} and {Chin-Hsien Lin} and {Tzu-Hsuan Chiang} and {Hua-Tsung Chen} and {Suh-Yin Lee}},
booktitle = {2015 IEEE International Conference on Multimedia {\&} Expo Workshops (ICMEW)},
doi = {10.1109/ICMEW.2015.7169855},
file = {:C$\backslash$:/Users/user/Documents/Mendeley Desktop/Chien-Li Chou et al.{\_}2015{\_}Coherent event-based surveillance video synopsis using trajectory clustering.pdf:pdf},
isbn = {978-1-4799-7079-7},
keywords = {Longest Common Subsequence (LCS),coherent event,surveillance,trajectory clustering,video summarization,video synopsis},
month = {Jun.},
pages = {1--6},
publisher = {IEEE},
title = {{Coherent event-based surveillance video synopsis using trajectory clustering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7169855},
year = {2015}
}
@article{Huang2014,
	author = {Huang, Chun-Rong and Chung, Pau-Choo Julia and Yang, Di-Kai and Chen, Hsing-Cheng and Huang, Guan-Jie},
	doi = {10.1109/TCSVT.2014.2308603},
	issn = {1051-8215},
	journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	month = {Aug.},
	number = {8},
	pages = {1417--1429},
	title = {{Maximum \emph{a Posteriori} Probability Estimation for Online Surveillance Video Synopsis}},
	url = {http://ieeexplore.ieee.org/document/6748870/},
	volume = {24},
	year = {2014}
}
@article{JianqingZhu2015,
	author = {{Jianqing Zhu} and {Shikun Feng} and {Dong Yi} and {Shengcai Liao} and {Zhen Lei} and Li, Stan Z},
	doi = {10.1109/TCSVT.2014.2363738},
	issn = {1051-8215},
	journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	month = {Jul.},
	number = {7},
	pages = {1113--1124},
	title = {{High-Performance Video Condensation System}},
	url = {http://ieeexplore.ieee.org/document/6928452/},
	volume = {25},
	year = {2015}
}
@article{Cooharojananone2015,
abstract = {Reviewing video surveillance contents for security monitoring is a time-consuming and time-limiting task. This paper presents a real-time video surveillance summarization framework intended for minimizing the time requirement for time critical tasks, based on compact moving objects in time-space. A tunnel is proposed as an individual time-dimension object. In order to summarize an endless video into a shorter duration without loss of selected targets so as to extend the understanding of any given individual object, this research utilizes three real-time algorithms. Direct shift collision detection (DSCD) is implemented for the extremely fast shifting of tunnels together in time-space. The DSCD summarized video can then be customized by technique from many different approaches. Here, early trajectory searching is applied with the same DSCD technique, and then direct distance transform is used to instantly give the trajectory similarity between tunnels and the user's query. The most important step for identifying each individual object is background subtraction. To this end, dynamic region adaptation (DRA) was used as the background subtraction algorithm to select the best foreground for each object before making a tunnel. DRA also helps DSCD to summarize the video more accurately. The proposed framework is able to provide the results by real-time performance approach without losing the major events of the original video stream.},
annote = {Cp2zj Times Cited:0 Cited References Count:21},
author = {Cooharojananone, Nagul and Kasamwattanarote, Siriwat and Lipikorn, Rajalida and Satoh, Shin'ichi},
doi = {10.1007/s11554-012-0280-7},
file = {:C$\backslash$:/Users/user/Documents/Mendeley Desktop/Cooharojananone et al.{\_}2015{\_}Automated real-time video surveillance summarization framework.pdf:pdf},
issn = {1861-8200},
journal = {Journal of Real-Time Image Processing},
keywords = {Background subtraction,Direct shift collision detection,Distance transform,Dynamic region adaptation,Film map generation,Foreground extraction,HOG,Just-in-time renderer,Object tracking,Tunnel processing,Video summarization,adaptation {\'{a}} background,detection {\'{a}},distance transform {\'{a}} film,map generation {\'{a}} just-in-time,renderer {\'{a}} dynamic region,tracking {\'{a}},tunnel processing {\'{a}} hog,video summarization {\'{a}} object,{\'{a}} direct shift collision},
language = {English},
month = {Sep.},
number = {3},
pages = {513--532},
title = {{Automated real-time video surveillance summarization framework}},
url = {http://link.springer.com/10.1007/s11554-012-0280-7},
volume = {10},
year = {2015}
}
@inproceedings{Zivkovic2004,
	author = {Zivkovic, Zoran},
	booktitle = {Proceedings of the 17th International Conference on Pattern Recognition},
	issn = {1051-4651},
	volume = {2},
	pages = {28--31},
	title = {{Improved adaptive Gaussian mixture model for background subtraction}},
	month = {Aug.},
	year = {2004},
	doi = {10.1109/ICPR.2004.1333992},
	url = {http://ieeexplore.ieee.org/document/1333992/},
}
@article{Zivkovic2006,
	title = {Efficient adaptive density estimation per image pixel for the task of background subtraction},
	author = {Zivkovic, Zoran and Van Der Heijden, Ferdinand},
	journal = {Pattern Recognition Letters},
	volume = {27},
	number = {7},
	pages = {773--780},
	month = {May},
	year = {2006},
	doi = {10.1016/j.patrec.2005.11.005}
	url = {https://doi.org/10.1016/j.patrec.2005.11.005}
}
@article{maddalena2008self,
	title={{A Self-Organizing Approach to Background Subtraction for Visual Surveillance Applications}},
	author={Maddalena, Lucia and Petrosino, Alfredo},
	journal={IEEE Transactions on Image Processing},
	volume={17},
	number={7},
	pages={1168--1177},
	month={Jul.},
	year={2008},
	doi={10.1109/TIP.2008.924285},
	url={https://ieeexplore.ieee.org/document/4527178}
}
@inproceedings{maddalena2012sobs,
	title={{The SOBS algorithm: What are the limits?}},
	author={Maddalena, Lucia and Petrosino, Alfredo},
	booktitle={2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
	pages={21--26},
	month={Jun.},
	year={2012},
	doi={10.1109/CVPRW.2012.6238922}, 
	url={https://ieeexplore.ieee.org/document/6238922}
}
@article{cuevas2013improved,
	title={Improved background modeling for real-time spatio-temporal non-parametric moving object detection strategies},
	author={Cuevas, Carlos and Garc{\'\i}a, Narciso},
	journal={Image and Vision Computing},
	volume={31},
	number={9},
	pages={616--630},
	month={Sep.},
	year={2013},
	doi={10.1016/j.imavis.2013.06.003},
	url={https://doi.org/10.1016/j.imavis.2013.06.003},
}
@article{haines2014background,
	title={{Background subtraction with DirichletProcess mixture models}},
	author={Haines, Tom SF and Xiang, Tao},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={36},
	number={4},
	pages={670--683},
	month={Apr.},
	year={2014},
	doi={10.1109/TPAMI.2013.239}, 
}
@article{cuevas2016labeled,
	title={Labeled dataset for integral evaluation of moving object detection algorithms: LASIESTA},
	author={Cuevas, Carlos and Y{\'a}{\~n}ez, Eva Mar{\'\i}a and Garc{\'\i}a, Narciso},
	journal={Computer Vision and Image Understanding},
	volume={152},
	pages={103--117},
	month = {Nov.},
	year={2016},
	publisher={Elsevier},
	url={https://doi.org/10.1016/j.cviu.2016.08.005}
}
@article{berjon2018real,
	title={Real-time nonparametric background subtraction with tracking-based foreground update},
	author={Berj{\'o}n, Daniel and Cuevas, Carlos and Mor{\'a}n, Francisco and Garc{\'\i}a, Narciso},
	journal={Pattern Recognition},
	volume={74},
	pages={156--170},
	month={Feb.},
	year={2018},
	doi={10.1016/j.patcog.2017.09.009},
	url={https://doi.org/10.1016/j.patcog.2017.09.009},
}
@inproceedings{Barnich2009ViBe,
	author = {O. Barnich and M. {Van Droogenbroeck}},
	title = {{ViBe}: A powerful random technique to estimate the background in video sequences},
	booktitle = {2009 IEEE International Conference on Acoustics, Speech and Signal Processing},
	pages = {945-948},
	month = {Apr.},
	year = {2009},
	doi = {10.1109/ICASSP.2009.4959741}, 
	url = {https://ieeexplore.ieee.org/document/4959741},
}
@article{Barnich2011ViBe,
	author = {O. Barnich and M. {Van Droogenbroeck}},
	title = {{ViBe}: A universal background subtraction algorithm for video sequences},
	journal = {IEEE Transactions on Image Processing},
	volume = {20},
	number = {6},
	pages = {1709-1724},
	month = {Jun.},
	year = {2011},
	doi = {10.1109/TIP.2010.2101613}, 
	url = {https://ieeexplore.ieee.org/document/5672785},
}
@inproceedings{VanDroogenbroeck2012Background,
	author = {M. {Van Droogenbroeck} and O. Paquot},
	title = {Background subtraction: Experiments and improvements for {ViBe}},
	booktitle = {2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
	pages = {32-37},
	month = {Jun.},
	year = {2012},
	doi={10.1109/CVPRW.2012.6238924},
	url = {https://ieeexplore.ieee.org/document/6238924} 
}
@incollection{VanDroogenbroeck2014ViBe,
	title = {{ViBe}: A Disruptive Method for Background Subtraction},
	booktitle = {Background Modeling and Foreground Detection for Video Surveillance},
	author = {M. {Van Droogenbroeck} and O. Barnich},
	editor = {T. Bouwmans and F. Porikli and B. Hoferlin and A. Vacavant},
	chapter = {7},
	pages = {7.1-7.23},
	month = {Jul.},
	year = {2014},
	publisher = {Chapman and Hall/CRC},
	doi = {10.1201/b17223-10},
	url = {http://hdl.handle.net/2268/157176},
}
@inproceedings{Hofmann2012,
	title = {{Background segmentation with feedback: The Pixel-Based Adaptive Segmenter}},
	author = {Hofmann, Martin and Tiefenbacher, Philipp and Rigoll, Gerhard},
	booktitle = {2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
	pages = {38--43},
	publisher = {IEEE},
	month = {Jun.},
	year = {2012},
	doi = {10.1109/CVPRW.2012.6238925},
	url = {http://ieeexplore.ieee.org/document/6238925/},
}
@article{Muchtar2018,
	author = {Muchtar, Kahlil and Rahman, Faris and Cenggoro, Tjeng Wawan and Budiarto, Arif and Pardamean, Bens},
	doi = {10.1016/j.procs.2018.08.228},
	issn = {18770509},
	journal = {Procedia Computer Science},
	pages = {579--586},
	publisher = {Elsevier B.V.},
	title = {{An Improved Version of Texture-based Foreground Segmentation: Block-based Adaptive Segmenter}},
	url = {https://doi.org/10.1016/j.procs.2018.08.228},
	volume = {135},
	year = {2018}
}
@article{Kirkpatrick1983,
	author = {Kirkpatrick, S and Gelatt, C D and Vecchi, M P},
	doi = {10.1126/science.220.4598.671},
	isbn = {9788578110796},
	issn = {0036-8075},
	journal = {Science},
	month = {May},
	number = {4598},
	pages = {671--680},
	pmid = {25246403},
	title = {{Optimization by Simulated Annealing}},
	url = {http://www.sciencemag.org/cgi/doi/10.1126/science.220.4598.671},
	volume = {220},
	year = {1983}
}
@article{Perez2003,
abstract = {Using generic interpolation machinery based on solving Poisson equations, a variety of novel tools are introduced for seamless editing of image regions. The rst set of tools permits the seamless importation of both opaque and transparent source image regions into a destination region. The second set is based on similar mathematical ideas and allows the user to modify the appearance of the image seamlessly, within a selected region. These changes can be arranged to affect the texture, the illumination, and the color of objects lying in the region, or to make tileable a rectangular selection.},
author = {P{\'{e}}rez, Patrick and Gangnet, Michel and Blake, Andrew},
doi = {10.1145/882262.882269},
file = {:C$\backslash$:/Users/user/Documents/Mendeley Desktop/Patrick, Gangnet, Blake{\_}2003{\_}Poisson Image Editing.pdf:pdf},
isbn = {1581137095},
issn = {07300301},
journal = {ACM Transactions on Graphics},
publisher = {ACM},
keywords = {guided in-,image gradient,interactive image editing,poisson equation,seamless cloning,selection editing,terpolation},
number = {3},
pages = {313--318},
pmid = {16786694},
title = {{Poisson image editing}},
url = {http://portal.acm.org/citation.cfm?doid=882262.882269},
volume = {22},
month = {Jul.},
year = {2003}
}
@article{Hoferlin2011,
	author = {H{\"{o}}ferlin, Benjamin and H{\"{o}}ferlin, Markus and Weiskopf, Daniel and Heidemann, Gunther},
	title = {{Information-based adaptive fast-forward for visual surveillance}},
	doi = {10.1007/s11042-010-0606-z},
	journal = {Multimedia Tools and Applications},
	month = {Oct.},
	number = {1},
	pages = {127--150},
	volume = {55},
	year = {2011},
	url = {https://doi.org/10.1007/s11042-010-0606-z},
}
@inproceedings{Smith1997,
	title = {{Video skimming and characterization through the combination of image and language understanding techniques}},
	author = {Smith, M.A. and Kanade, T.},
	booktitle = {Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	pages = {775--781},
	month = {Jun.},
	year = {1997},
	doi = {10.1109/CVPR.1997.609414},
	url = {http://ieeexplore.ieee.org/document/609414/},
}
@article{Kuhn1955,
	title = {{The Hungarian method for the assignment problem}},
	author = {Kuhn, H. W.},
	journal = {Naval Research Logistics Quarterly},
	volume = {2},
	number = {1-2},
	pages = {83--97},
	month = {Mar.},
	year = {1955},
	doi = {10.1002/nav.3800020109},
	url = {http://doi.org/10.1002/nav.3800020109},
}
@article{kuhn1956variants,
	title={{Variants of the Hungarian method for assignment problems}},
	author={Kuhn, Harold W},
	journal={Naval Research Logistics Quarterly},
	volume={3},
	number={4},
	pages={253--258},
	month={Dec.},
	year={1956},
	doi={10.1002/nav.380000404},
	url={https://doi.org/10.1002/nav.3800030404},
}
@article{munkres1957algorithms,
	title={Algorithms for the assignment and transportation problems},
	author={Munkres, James},
	journal={Journal of the Society for Industrial and Applied Mathematics},
	volume={5},
	number={1},
	pages={32--38},
	month={Mar.},
	year={1957},
	doi={10.1137/0105003},
	url={https://doi.org/10.1137/0105003},
}
@article{bourgeois1971extension,
	title={{An extension of the Munkres algorithm for the assignment problem to rectangular matrices}},
	author={Bourgeois, Fran{\c{c}}ois and Lassalle, Jean-Claude},
	journal={Communications of the ACM},
	volume={14},
	number={12},
	pages={802--804},
	month={Dec.},
	year={1971},
	doi={10.1145/362919.362945},
	url={http://doi.acm.org/10.1145/362919.362945},
}
@book{Oppenheim2009,
author = {Oppenheim, Alan V and Schafer, Ronald W},
edition = {3rd},
publisher = {Pearson},
isbn = {0132067099},
pages = {742--774},
title = {Discrete Time Signal Processing},
year = {2010}
}
@book{Cormen2009,
author = {Cormen, Thomas H and Leiserson, Charles E and Rivest, Ronald L and Stein, Clifford},
edition = {3rd},
publisher = {MIT press},
isbn = {9780262033848},
pages = {414--450},
title = {Introduction to algorithms},
year = {2009}
}
@article{Petrovic2005,
	author = {Petrovic, Nemanja and Jojic, Nebojsa and Huang, Thomas S.},
	doi = {10.1007/s11042-005-0895-9},
	issn = {1380-7501},
	journal = {Multimedia Tools and Applications},
	month = {Aug.},
	number = {3},
	pages = {327--344},
	title = {{Adaptive Video Fast Forward}},
	url = {https://doi.org/10.1007/s11042-005-0895-9},
	volume = {26},
	year = {2005}
}
@article{Kolmogorov2004,
	author = {Kolmogorov, Vladimir and Zabih, Ramin},
	title = {{What energy functions can be minimized via graph cuts?}},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume = {26},
	number = {2},
	pages = {147--159},
	month = {Feb.},
	year = {2004},
	doi = {10.1109/TPAMI.2004.1262177},
	url = {http://ieeexplore.ieee.org/document/1262177/},
}
@misc{bouwmans2018deep,
	title={Deep Neural Network Concepts for Background Subtraction: A Systematic Review and Comparative Evaluation},
	author={Thierry Bouwmans and Sajid Javed and Maryam Sultana and Soon Ki Jung},
	year={2018},
	eprint={1811.05255},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}
@article{Sakkos2019,
	author = {Sakkos, Dimitrios and Ho, Edmond S. L. and Shum, Hubert P. H.},
	doi = {10.1109/ACCESS.2019.2891943},
	issn = {2169-3536},
	journal = {IEEE Access},
	pages = {10976--10986},
	title = {{Illumination-Aware Multi-Task GANs for Foreground Segmentation}},
	url = {https://ieeexplore.ieee.org/document/8606933/},
	volume = {7},
	month = {Jan.},
	year = {2019}
}
@inproceedings{Bakkay2018,
	title = {{BSCGAN: Deep Background Subtraction with Conditional Generative Adversarial Networks}},
	author = {Bakkay, M. C. and Rashwan, H. A. and Salmane, H. and Khoudour, L. and Puigtt, D. and Ruichek, Y.},
	booktitle = {2018 25th IEEE International Conference on Image Processing},
	pages = {4018--4022},
	month = {Oct.},
	year = {2018},
	doi = {10.1109/ICIP.2018.8451603},
	url = {https://ieeexplore.ieee.org/document/8451603/},
}
@article{Sultana2019,
	author = {Sultana, Maryam and Mahmood, Arif and Javed, Sajid and Jung, Soon Ki},
	doi = {10.1007/s00138-018-0993-0},
	issn = {0932-8092},
	journal = {Machine Vision and Applications},
	month = {Apr.},
	number = {3},
	pages = {375--395},
	publisher = {Springer Berlin Heidelberg},
	title = {{Unsupervised deep context prediction for background estimation and foreground segmentation}},
	url = {https://doi.org/10.1007/s00138-018-0993-0},
	volume = {30},
	year = {2019}
}
@article{Patil2018,
	author = {Patil, Prashant W. and Murala, Subrahmanyam},
	doi = {10.1109/TITS.2018.2880096},
	issn = {1524-9050},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	mendeley-groups = {background modeling},
	pages = {1--12},
	publisher = {IEEE},
	title = {{MSFgNet: A Novel Compact End-to-End Deep Network for Moving Object Detection}},
	url = {https://ieeexplore.ieee.org/document/8546771/},
	month = {Nov.},
	year = {2018}
}
@article{Lim2018,
	author = {Lim, Long Ang and {Yalim Keles}, Hacer},
	doi = {10.1016/j.patrec.2018.08.002},
	issn = {01678655},
	journal = {Pattern Recognition Letters},
	pages = {256--262},
	publisher = {Elsevier},
	title = {{Foreground segmentation using convolutional neural networks for multiscale feature encoding}},
	url = {https://doi.org/10.1016/j.patrec.2018.08.002},
	volume = {112},
	month = {Sep.},
	year = {2018}
}
@article{Everingham15, 
	title={{The \textsc{PASCAL} Visual Object Classes Challenge: A Retrospective}}, 
	author = "Everingham, M. and Eslami, S. M. A. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.",
	journal = "International Journal of Computer Vision", 
	volume = "111", 
	number = "1", 
	pages = "98--136", 
	month = "Jan.", 
	year = "2015", 
	doi={10.1007/s11263-014-0733-5},
	url={https://doi.org/10.1007/s11263-014-0733-5},
} 
@inproceedings{Cordts2016Cityscapes,
	title={{The Cityscapes Dataset for Semantic Urban Scene Understanding}},
	author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
	booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition},
	pages={3213-3223}, 
	month={Jun.},
	year={2016},
	doi={10.1109/CVPR.2016.350}, 
	url={https://ieeexplore.ieee.org/document/7780719},
}
@misc{chen2014semantic,
	title={{Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs}},
	author={Liang-Chieh Chen and George Papandreou and Iasonas Kokkinos and Kevin Murphy and Alan L. Yuille},
	year={2014},
	eprint={1412.7062},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}
@inproceedings{Long2015,
	title = {{Fully convolutional networks for semantic segmentation}},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	booktitle = {2015 IEEE Conference on Computer Vision and Pattern Recognition},
	pages = {3431--3440},
	publisher = {IEEE},
	month = {Jun.},
	year = {2015},
	doi = {10.1109/CVPR.2015.7298965},
	url = {http://ieeexplore.ieee.org/document/7298965/},
}
@misc{chen2017rethinking,
	title={{Rethinking Atrous Convolution for Semantic Image Segmentation}},
	author={Liang-Chieh Chen and George Papandreou and Florian Schroff and Hartwig Adam},
	year={2017},
	eprint={1706.05587},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}
@inproceedings{Zhao2017,
	title = {{Pyramid Scene Parsing Network}},
	author = {Zhao, Hengshuang and Shi, Jianping and Qi, Xiaojuan and Wang, Xiaogang and Jia, Jiaya},
	booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition},
	month = {Jul.},
	pages = {6230--6239},
	year = {2017},
	doi = {10.1109/CVPR.2017.660},
	url = {http://ieeexplore.ieee.org/document/8100143/},
}
@article{chen2018deeplab, 
	title={{DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs}}, 
	author={L. {Chen} and G. {Papandreou} and I. {Kokkinos} and K. {Murphy} and A. L. {Yuille}}, 
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
	volume={40}, 
	number={4}, 
	pages={834-848},
	month={Apr.},
	year={2018}, 
	doi={10.1109/TPAMI.2017.2699184}, 
	url={https://ieeexplore.ieee.org/document/7913730},
}
@inproceedings{chen2018encoder,
	title={{Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation}},
	author={Chen, Liang-Chieh and Zhu, Yukun and Papandreou, George and Schroff, Florian and Adam, Hartwig},
	booktitle={15th European Conference on Computer Vision},
	pages={833-851},
	month={Sep.},
	year={2018},
	doi={10.1007/978-3-030-01234-2_49},
	url={https://doi.org/10.1007/978-3-030-01234-2\_49},
}
@inproceedings{perez2002color,
	title={{Color-Based Probabilistic Tracking}},
	author={P{\'e}rez, Patrick and Hue, Carine and Vermaak, Jaco and Gangnet, Michel},
	booktitle={7th European Conference on Computer Vision},
	pages={661--675},
	month={May},
	year={2002},
	doi={10.1007/3-540-47969-4_44},
	url={https://doi.org/10.1007/3-540-47969-4\_44},
}